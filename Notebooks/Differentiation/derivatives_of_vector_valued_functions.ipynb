{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main message\n",
    "Derivatives of a scalar with respect to a scalar might be relatively straightforward. Derivatives of vector valued functions are not impossibly difficult. You can use intelligent matrix and array operations to facilitate the process.\n",
    "\n",
    "## What are vector valued functions?\n",
    "A vector valued function is any function that returns multiple values (outputs). These are quite common in engineering models; rarely do we only care about scalar inputs and scalar outputs to a model. Here are some examples of vector valued functions in the wild:\n",
    "- structural stresses in different members in an aircraft wing\n",
    "- thickness of the tower for a wind turbine from base to top\n",
    "- thrust outputs of an engine at different operating points\n",
    "- altitude of an aircraft along different points in its trajectory\n",
    "\n",
    "Intuitively, each of these quantities should be considered together, so it makes sense to contain them within a vector or array. You *could* consider each of them as scalar values, but it would be unreasonably difficult to track them through your model and perform computations efficiently.\n",
    "\n",
    "In a general sense, think of a \"vector\" as including arbitrarily dimensioned arrays and tensors. Strictly mathematically, \"vector valued functions\" only refer to functions that produce multidimensional outputs, but this lesson is relevant even in the case of multidimensional inputs and single-dimensional outputs. I'll be covering the general case of arbitrarily sized inputs and outputs.\n",
    "\n",
    "Here are some three examples of engineering functions that are not scalar-to-scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Angle between two 3D vectors\n",
    "Despite having 6 inputs, because the output is scalar, this is technically not a vector valued function. It's still quite a relevant engineering function. Don't read too much into the proper definition of \"vector valued function\" and what's included or not, just know that in this lesson we're talking about anything that's not a scalar-to-scalar function.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  {\\bf a} &= \\begin{bmatrix}\n",
    "          a_{x} \\\\\n",
    "          a_{y} \\\\\n",
    "          a_{z} \\\\\n",
    "        \\end{bmatrix}\n",
    "\\end{align*}\n",
    ", \\quad\n",
    "\n",
    "\\begin{align*}\n",
    "  {\\bf b} &= \\begin{bmatrix}\n",
    "          b_{x} \\\\\n",
    "          b_{y} \\\\\n",
    "          b_{z} \\\\\n",
    "        \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = \\cos^{-1}\\biggl(\\frac{{\\bf a} \\cdot {\\bf b}}{|{\\bf a}| |{\\bf b}|}\\biggr)\n",
    "$$\n",
    "\n",
    "\n",
    "### Exit velocity of a tennis ball in 2D\n",
    "I've got a backyard tennis ball launcher where you can choose the launch angle and speed. Let's ignore the 3-dimensional aspect of the world right now and think in 2D. This results in a two dimensional input (launch angle and speed) and a two dimensional output for the velocity (x and y components). This **is** a vector valued function.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  {\\bf v} &= \\begin{bmatrix}\n",
    "          v_{x} \\\\\n",
    "          v_{y} \\\\\n",
    "        \\end{bmatrix} &= \\begin{bmatrix}\n",
    "          v \\cos(\\theta) \\\\\n",
    "          v \\sin(\\theta) \\\\\n",
    "        \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "### Force-displacement history for an automotive shock absorber\n",
    "Let's say you're a suspension engineer for a car company. You are trying to model the displacement of the suspension system across a car's simulated route. Simplifying a lot of physics, we can obtain the displacement ($x$) of the shock absorber by knowing the force ($F$) acting on it and the spring constant ($k$): $x = F/k$. Given a recording of force measurements from 1000 timepoints in a lab test, we can compute the corresponding shock displacement at each point.\n",
    "\n",
    "This results in 1000 inputs and 1000 outputs and this is a vector valued function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief math theory of derivative arrays (Jacobians)\n",
    "\n",
    "I'll now detail some basic theory behind the derivatives of vector valued functions. Sec. 6.1 in [Engineering Design Optimization](https://mdobook.github.io/) also presents this information.\n",
    "\n",
    "In the case of a function $f(x)$ where the input and output are both scalars, we get:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\underset{1\\times 1}{\\frac{\\partial f}{\\partial x}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In the general case we have an array called the *Jacobian* which contains the gradient information for vector valued functions. Its size is based on the number of inputs $n_x$ and the number of outputs $n_f$ as such:\n",
    "\n",
    "$$\n",
    "J_{f}=\\frac{\\partial f}{\\partial x}=\\left[\\begin{array}{c}\n",
    "\\nabla f_{1}^\\intercal \\\\\n",
    "\\vdots \\\\\n",
    "\\nabla f_{n_{f}}^\\intercal\n",
    "\\end{array}\\right]=\\underbrace{\\left[\\begin{array}{ccc}\n",
    "\\frac{\\partial f_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{1}}{\\partial x_{n_{x}}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_{n_{f}}}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{n_{f}}}{\\partial x_{n_{x}}}\n",
    "\\end{array}\\right]}_{\\left(n_{f} \\times n_{x}\\right)}\n",
    "$$\n",
    "\n",
    "Here is a reproduction of Ex. 6.1 from [Engineering Design Optimization](https://mdobook.github.io/) to show how to obtain the derivatives of a simple vector valued function.\n",
    "\n",
    "$$\n",
    "f(x)=\\left[\\begin{array}{l}\n",
    "f_{1}\\left(x_{1}, x_{2}\\right) \\\\\n",
    "f_{2}\\left(x_{1}, x_{2}\\right)\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "x_{1} x_{2}+\\sin x_{1} \\\\\n",
    "x_{1} x_{2}+x_{2}^{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Differentiating symbolically, we get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x}=\\left[\\begin{array}{cc}\n",
    "x_{2}+\\cos x_{1} & x_{1} \\\\\n",
    "x_{2} & x_{1}+2 x_{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Evaluating this at $x=(\\pi/4, 2)$ yields\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x}=\\left[\\begin{array}{ll}\n",
    "2.707 & 0.785 \\\\\n",
    "2.000 & 4.785\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of computing the Jacobian entries as individually computing derivatives of scalars with respect to scalars and putting them in an array. But I would not suggest thinking that way, especially in more complex cases. It's helpful to know that deep down all vector valued functions are just scalar functions smashed together. Often times, though, there will be patterns in the derivatives that you should harness when computing Jacobians for vector valued functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example case in OpenMDAO\n",
    "\n",
    "Here's a simple example case implemented in OpenMDAO where we have three inputs and two outputs. We sum each neighboring value in the input vector to obtain the output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7. 15.]\n"
     ]
    }
   ],
   "source": [
    "import openmdao.api as om\n",
    "\n",
    "\n",
    "class SystemOfEquations(om.ExplicitComponent):\n",
    "    def setup(self):\n",
    "        self.add_input('x', shape=3)\n",
    "        self.add_output('f', shape=2)\n",
    "\n",
    "    def compute(self, inputs, outputs):\n",
    "        outputs['f'][0] = inputs['x'][0] + inputs['x'][1]\n",
    "        outputs['f'][1] = inputs['x'][1] + inputs['x'][2]\n",
    "\n",
    "\n",
    "prob = om.Problem()\n",
    "prob.model.add_subsystem('subsystem', SystemOfEquations(), promotes=['*'])\n",
    "\n",
    "prob.setup()\n",
    "prob.set_val('x', [2., 5., 10.])\n",
    "\n",
    "prob.run_model()\n",
    "print(prob['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay that's great, but we haven't implemented the derivatives for this component. Let's do that now. It's sort of a ridiculously simple case but I'm doing it on purpose so that we are not distracted by the complexity of the derivatives.\n",
    "\n",
    "We rewrite the previous component and add analytic derivatives in the `compute_partials` method. Then, we check those derivatives against a finite difference approximation using the `check_partials` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Component: SystemOfEquations 'subsystem'\n",
      "----------------------------------------\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "'f'        wrt 'x'          | 2.0000e+00 | 2.0000e+00 | 1.2868e-09 | 6.4340e-10\n",
      "\n",
      "#######################################################################\n",
      "Sub Jacobian with Largest Relative Error: SystemOfEquations 'subsystem'\n",
      "#######################################################################\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "'f'        wrt 'x'          | 2.0000e+00 | 2.0000e+00 | 1.2868e-09 | 6.4340e-10\n"
     ]
    }
   ],
   "source": [
    "class SystemOfEquations(om.ExplicitComponent):\n",
    "    def setup(self):\n",
    "        self.add_input('x', shape=3)\n",
    "        self.add_output('f', shape=2)\n",
    "        self.declare_partials(of='f', wrt='x')\n",
    "\n",
    "    def compute(self, inputs, outputs):\n",
    "        outputs['f'][0] = inputs['x'][0] + inputs['x'][1]\n",
    "        outputs['f'][1] = inputs['x'][1] + inputs['x'][2]\n",
    "\n",
    "    def compute_partials(self, inputs, partials):\n",
    "        partials['f', 'x'][0, 0] = 1.\n",
    "        partials['f', 'x'][0, 1] = 1.\n",
    "        partials['f', 'x'][1, 1] = 1.\n",
    "        partials['f', 'x'][1, 2] = 1.\n",
    "\n",
    "prob = om.Problem()\n",
    "prob.model.add_subsystem('subsystem', SystemOfEquations(), promotes=['*'])\n",
    "\n",
    "prob.setup()\n",
    "prob.set_val('x', [2., 5., 10.])\n",
    "\n",
    "prob.run_model()\n",
    "prob.check_partials(compact_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now of course, that was a trivially simple system. But I want to highlight some improvements to the code.\n",
    "\n",
    "The first is that because all the derivative values are constant and do not depend on the input values, we can simply declare them in the `setup` method instead of using the `compute_partials` method. This will instead tell OpenMDAO the derivative values and that they never change. This is only possible for certain types of functions but saves computational cost by avoiding running computations in `compute_partials` unnecessarily.\n",
    "\n",
    "Let's give this a naive try below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Component: SystemOfEquations 'subsystem'\n",
      "----------------------------------------\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "'f'        wrt 'x'          | 2.4495e+00 | 2.0000e+00 | 1.4142e+00 | 7.0711e-01 >ABS_TOL >REL_TOL\n",
      "\n",
      "#######################################################################\n",
      "Sub Jacobian with Largest Relative Error: SystemOfEquations 'subsystem'\n",
      "#######################################################################\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "'f'        wrt 'x'          | 2.4495e+00 | 2.0000e+00 | 1.4142e+00 | 7.0711e-01\n"
     ]
    }
   ],
   "source": [
    "class SystemOfEquations(om.ExplicitComponent):\n",
    "    def setup(self):\n",
    "        self.add_input('x', shape=3)\n",
    "        self.add_output('f', shape=2)\n",
    "        self.declare_partials(of='f', wrt='x', val=1.)\n",
    "\n",
    "    def compute(self, inputs, outputs):\n",
    "        outputs['f'][0] = inputs['x'][0] + inputs['x'][1]\n",
    "        outputs['f'][1] = inputs['x'][1] + inputs['x'][2]\n",
    "\n",
    "prob = om.Problem()\n",
    "prob.model.add_subsystem('subsystem', SystemOfEquations(), promotes=['*'])\n",
    "\n",
    "prob.setup()\n",
    "prob.set_val('x', [2., 5., 10.])\n",
    "\n",
    "prob.run_model()\n",
    "prob.check_partials(compact_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative check didn't pass! Maybe it's obvious to you or maybe it's not clear why this is the case. After all, each of the derivative values we computed were 1, and then we said the Jacobian entry values are 1. However, only *some* of them are 1. I've fallen victim to thinking about this incorrectly before. We need to tell OpenMDAO *which* values are 1. Here's how we can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Component: SystemOfEquations 'subsystem'\n",
      "----------------------------------------\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "'f'        wrt 'x'          | 2.0000e+00 | 2.0000e+00 | 1.2868e-09 | 6.4340e-10\n",
      "\n",
      "#######################################################################\n",
      "Sub Jacobian with Largest Relative Error: SystemOfEquations 'subsystem'\n",
      "#######################################################################\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "'f'        wrt 'x'          | 2.0000e+00 | 2.0000e+00 | 1.2868e-09 | 6.4340e-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class SystemOfEquations(om.ExplicitComponent):\n",
    "    def setup(self):\n",
    "        self.add_input('x', shape=3)\n",
    "        self.add_output('f', shape=2)\n",
    "\n",
    "        jac = np.array([[1., 1., 0.],\n",
    "                        [0., 1., 1.]])\n",
    "        self.declare_partials(of='f', wrt='x', val=jac)\n",
    "\n",
    "    def compute(self, inputs, outputs):\n",
    "        outputs['f'][0] = inputs['x'][0] + inputs['x'][1]\n",
    "        outputs['f'][1] = inputs['x'][1] + inputs['x'][2]\n",
    "\n",
    "prob = om.Problem()\n",
    "prob.model.add_subsystem('subsystem', SystemOfEquations(), promotes=['*'])\n",
    "\n",
    "prob.setup()\n",
    "prob.set_val('x', [2., 5., 10.])\n",
    "\n",
    "prob.run_model()\n",
    "prob.check_partials(compact_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, we did it better! But what if our component is dealing with bigger input and output dimensionality? Let's generalize what we've done and make it a little slicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Component: SystemOfEquations 'subsystem'\n",
      "----------------------------------------\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "'f'        wrt 'x'          | 1.4142e+01 | 1.4142e+01 | 1.9768e-09 | 1.3978e-10\n",
      "\n",
      "#######################################################################\n",
      "Sub Jacobian with Largest Relative Error: SystemOfEquations 'subsystem'\n",
      "#######################################################################\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "'f'        wrt 'x'          | 1.4142e+01 | 1.4142e+01 | 1.9768e-09 | 1.3978e-10\n"
     ]
    }
   ],
   "source": [
    "class SystemOfEquations(om.ExplicitComponent):\n",
    "    def setup(self):\n",
    "        # Set the size of the input and output\n",
    "        n = 100\n",
    "        self.add_input('x', shape=n+1)\n",
    "        self.add_output('f', shape=n)\n",
    "\n",
    "        # Construct an array and fill it with the Jacobian info\n",
    "        jac = np.zeros((n, n+1))\n",
    "        arange = np.arange(n)\n",
    "        jac[arange, arange] = 1.\n",
    "        jac[arange, arange+1] = 1.\n",
    "        \n",
    "        # Give this Jacobian to OpenMDAO\n",
    "        self.declare_partials(of='f', wrt='x', val=jac)\n",
    "\n",
    "    def compute(self, inputs, outputs):\n",
    "        # Loop through all the indices and add up the two neighboring\n",
    "        # inpupt values to obtain the output values\n",
    "        for idx, f in enumerate(outputs['f']):\n",
    "            outputs['f'][idx] = inputs['x'][idx] + inputs['x'][idx+1]\n",
    "\n",
    "prob = om.Problem()\n",
    "prob.model.add_subsystem('subsystem', SystemOfEquations(), promotes=['*'])\n",
    "\n",
    "prob.setup()\n",
    "\n",
    "prob.run_model()\n",
    "prob.check_partials(compact_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have a system and its corresponding derivatives set up in a very general and pretty efficient way. The number of lines of code we needed to use to handle a bigger system wasn't that bad. Of course there are some improvements we can make, but for now that's pretty good.\n",
    "\n",
    "Zooming out from this simple case, there are many intricacies and subtlties to obtaining derivatives of vector valued functions. Depending on your model and problems, they may or may not be worth considering. We'll detail a few of them in the next few sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity in the Jacobian can be exploited\n",
    "\n",
    "In the immediately prior example we had a 100x101 Jacobian but only 200 non-zero entries. That's about 2% of the array occupied by numbers! There's 98% of that array just sitting these doing nothing! We can take advantage of that sparsity.\n",
    "\n",
    "For large problems we want to avoid instantiating Jacobian arrays in a \"dense\" fashion if they are quite sparse. In our prior example, we had a dense and largely empty array. Instead, we should represent our Jacobian in a \"sparse\" way by only telling OpenMDAO about the non-zero entries.\n",
    "\n",
    "Problems with sparse gradient arrays are quite common in engineering. Here are a few cases:\n",
    "- The flow properties within a CFD cell only depend directly on the nearby geometry.\n",
    "- For an aircraft trajectory the lift and drag at a quasi-steady point are only dependent on the current flight conditions. No other points in the time history affect that performance.\n",
    "- The support structure for a small scale wind turbine consists of many small steel beams welded together. There is inherent sparsity in the gradients for this structure, e.g. increasing the thickness of a beam at the base of the support does not change the properties of a beam at the top of the tower.\n",
    "\n",
    "Let's revisit the example case from above and take advantage of the sparsity inherent in this problem using [OpenMDAO's sparsity support.](https://openmdao.org/newdocs/versions/latest/features/core_features/working_with_derivatives/sparse_partials.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Component: SystemOfEquations 'subsystem'\n",
      "----------------------------------------\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "'f'        wrt 'x'          | 1.4142e+01 | 1.4142e+01 | 1.9768e-09 | 1.3978e-10\n",
      "\n",
      "#######################################################################\n",
      "Sub Jacobian with Largest Relative Error: SystemOfEquations 'subsystem'\n",
      "#######################################################################\n",
      "\n",
      "'<output>' wrt '<variable>' | calc mag.  | check mag. | a(cal-chk) | r(cal-chk)\n",
      "-------------------------------------------------------------------------------\n",
      "'f'        wrt 'x'          | 1.4142e+01 | 1.4142e+01 | 1.9768e-09 | 1.3978e-10\n"
     ]
    }
   ],
   "source": [
    "class SystemOfEquations(om.ExplicitComponent):\n",
    "    def setup(self):\n",
    "        # Set the size of the input and output\n",
    "        n = 100\n",
    "        self.add_input('x', shape=n+1)\n",
    "        self.add_output('f', shape=n)\n",
    "\n",
    "        # Construct arrays for the indices for the sparse array.\n",
    "        # Through this, OpenMDAO never creates a dense array for the Jacobian\n",
    "        # and instead uses a sparse array representation.\n",
    "        arange = np.arange(n)\n",
    "        rows = np.hstack((arange, arange))\n",
    "        cols = np.hstack((arange, arange+1))\n",
    "        \n",
    "        # Give this Jacobian to OpenMDAO\n",
    "        self.declare_partials(of='f', wrt='x', val=1., rows=rows, cols=cols)\n",
    "\n",
    "    def compute(self, inputs, outputs):\n",
    "        # Loop through all the indices and add up the two neighboring\n",
    "        # inpupt values to obtain the output values\n",
    "        for idx, f in enumerate(outputs['f']):\n",
    "            outputs['f'][idx] = inputs['x'][idx] + inputs['x'][idx+1]\n",
    "\n",
    "prob = om.Problem()\n",
    "prob.model.add_subsystem('subsystem', SystemOfEquations(), promotes=['*'])\n",
    "\n",
    "prob.setup()\n",
    "\n",
    "prob.run_model()\n",
    "prob.check_partials(compact_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse derivatives are not always fixed values. In general, you can declare the sparsity of the Jacobian in your `setup` method and then fill in the actual values of those non-zero Jacobian entries in the `compute_partials` method.\n",
    "\n",
    "It's easy to encounter models with sparsity patterns that are much more complex than what I've shown in the examples. Sometimes it's challenging to even recognize the sparsity pattern, let alone put it into code and compute the derivatives. Luckily, OpenMDAO has some helpful tools built in that can reduce your effort.\n",
    "\n",
    "One of those helpful tools is the `view_coloring` command-line tool, shown on [this doc page](https://openmdao.org/newdocs/versions/latest/features/core_features/working_with_derivatives/simul_derivs.html). Although it's called `view_coloring`, it also helps you see the sparsity pattern for your components or systems, as shown in the example image below. The next section explains coloring in more detail.\n",
    "\n",
    "I find this visual to be quite helpful when I'm trying to figure out the sparsity pattern for my systems, especially because it's challenging to see patterns when looking at text or math but it's much easier to see those patterns visually.\n",
    "\n",
    "![View coloring results](coloring_viewer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative coloring can also help\n",
    "\n",
    "\"Coloring\" is the idea that multiple derivative values can be computed simultaneously because those derivatives have no effect on each other. The name comes from the idea of coloring the Jacobian based on the values that are independent of each other, using the minimum number of colors possible. Think of coloring the countries on a map where any bordering country has a different color from its neighbors.\n",
    "\n",
    "Coloring decreases the computational cost associated with computing derivatives when your model has separable functions of interest. [This doc page](http://openmdao.org/twodocs/versions/latest/theory_manual/advanced_linear_solvers_special_cases/separable.html) goes into much more detail and has some fantastic visuals.\n",
    "\n",
    "Please see other lessons for a more detailed examination of coloring, specifically [[Partial derivative coloring]] and [[Total derivative coloring]].\n",
    "\n",
    "For the purposes of this lesson, know that coloring can help decrease the cost of computing gradients for vector valued functions. If your model is too expensive during derivative computation, you can look into using coloring to decrease the time to solve the linear system.\n",
    "\n",
    "[This doc page](https://openmdao.org/newdocs/versions/latest/features/core_features/working_with_derivatives/simul_derivs.html) is helpful for more info on how to look at coloring within problems in OpenMDAO and [this page](https://openmdao.org/newdocs/versions/latest/features/experimental/approx_coloring.html) is helpful if you are approximating your derivatives, e.g. using finite difference or complex step. [This last page on setting up linear solvers](https://openmdao.org/newdocs/versions/latest/theory_manual/setup_linear_solvers.html) is also relevant for some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other resources\n",
    "\n",
    "This lesson just introduces and scratches the surface of getting derivatives of vector valued functions. Other lessons will go into detail about more advanced techniques and performance improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc39345f4c71044b590c101e46f267e23dd1cedaed1cdb4d1403963d20608f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
