tags: #optimization

## Main message
Gradient-based optimizers are the most efficient way to explore highly dimensional design spaces and find optimal designs.

## Gradient-based optimizers are quite efficient
- they intelligently explore the design space
- when paired with efficient derivative computation methods, they work quite well for highly dimensional problems
- show the famous plot and explain what it means

## Mathematically, it's helpful for optimization
- you better understand what type of optima you have
- as compared to other methods, convergence is more easily understood

## Considerations
- limited to continuous problems
- may need to use multiple starts to better explore the design space